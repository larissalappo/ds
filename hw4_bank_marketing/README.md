Домашняя работа №4
Реализовать минимум 5 классификаторов, сравнить метрики между собой, выбрать лучший для Вашего датасета.
Классификаторы:
Классификатор градиентного бустинга. 
Классификатор CatBoost. 
Классификатор Ada Boost. 
Классификатор Extra Trees. 
Квадратичный дискриминантный анализ. 	
Light Gradient Boosting Machine. 
Классификатор K Neighbors.  
Классификатор дерева решений. 
Экстремальный градиентный бустинг.
Фиктивный классификатор.  
SVM - линейное ядро.

Датасет:  Bank Marketing (bank-additional-full.csv) 
(http://archive.ics.uci.edu/dataset/222/bank+marketing)

Задача:
Обучить модель классификации для предсказания, откроет ли клиент срочный депозит

Входные переменные:

данные о клиентах банка:
   1 - age - возраст 
   2 - job - работа
   3 - marital - семейное положение
   4 - education - образование
   5 - default - задолженность по кредитам
   6 - housing - кредит на недвижимость
   7 - loan - кредит на потребительские нужды

прошлый контакт в рамках текущей компании:
   8 - contact - тип контакта (моб/стац телефон)
   9 - month - месяц
  10 - day_of_week - день
  11 - duration - продолжительность прошлого контакта

доп параметры:
  12 - campaign - количество контактов, выполненных в ходе этой маркетинговой кампании и для этого клиента
  13 - pdays - количество дней, прошедших после последнего контакта с клиентом из предыдущей кампании
  14 - previous - количество контактов, выполненных до этой кампании и для этого клиента
  15 - poutcome - результат предыдущей маркетинговой кампании
  
атрибуты социального и экономического контекста
  16 - emp.var.rate - коэффициент изменения уровня занятости - квартальный показатель
  17 - cons.price.idx - индекс потребительских цен - месячный показатель     
  18 - cons.conf.idx - индекс доверия потребителей - месячный показатель   
  19 - euribor3m - межбанковская %-я ставка в евро
  20 - nr.employed - количество работающих

Выходной параметр (целевая переменная):
  21 - y - откроет ли клиент срочный депозит?


Результаты:

Лучшие результаты показал алгоритм GradientBoostingClassifier 

Худшие результаты ожидаемо показал алгоритм Dummy Classifier (был выбран, чтобы "потрогать дно"): во всех предсказаниях выбрал 0 (нет) и при этом accuracy = 0.89 (т.к. в датасете классы не сбалансированы)


